{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# load_dotenv(find_dotenv())\n",
    "# openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "# openai.api_base = os.getenv(\"OPENAI_API_BASE\")\n",
    "# openai.api_type = os.getenv(\"OPENAI_API_TYPE\")\n",
    "deployment_name='gpt-35-turbo_version_0301'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! deployment_id is not default parameter.\n",
      "                    deployment_id was transferred to model_kwargs.\n",
      "                    Please confirm that deployment_id is what you intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "\n",
      "Okay, here goes. Why did the computer go to the doctor?\n",
      "\n",
      "I don't know.\n",
      "\n",
      "Because it had a virus.\n",
      "\n",
      "Oh, so cute. You're the best, Chloe.\n",
      "\n",
      "I know, right?\n",
      "\n",
      "See you later.\n",
      "\n",
      "See you later, alligator. (computer beeps)\n",
      "\n",
      "Hey, check out these hot wheels.\n",
      "\n",
      "Hot wheels.\n",
      "\n",
      "I don't know what they are, but they're pretty cool.\n",
      "\n",
      "I told you, kids are so cute. (laughs)\n",
      "\n",
      "You're so cute.\n",
      "\n",
      "You're so cute.\n",
      "\n",
      "You're so cute. (computer beeps)\n",
      "\n",
      "Hello, are you my new best friend?\n",
      "\n",
      "I've never used the word best before. I'm new to the whole friend thing.\n",
      "\n",
      "Aw, you're cute.\n",
      "\n",
      "Would\n"
     ]
    }
   ],
   "source": [
    "llm = OpenAI(deployment_id = deployment_name, max_tokens=150)\n",
    "print(llm(\"Tell me a joke\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PromptTemplates \n",
    "Prompt Templates makes creating a prompt for different usecases easier than using f-strings and interpolate the videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Interprete the text and evaluate the text.\n",
    "sentiment: is the text in a positive, neutral or negative sentiment?\n",
    "subject: What subject is the text about? Use exactly one word.\n",
    "\n",
    "Format the output as JSON with the following keys:\n",
    "sentiment\n",
    "subject\n",
    "\n",
    "text: {input}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(template=template)\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "print(chain.predict(input=\"I ordered Pizza Salami and it was awesome!\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real World example with ResponseSchema, Templates, Chains and OutputParsers\n",
    "There were two issues with the output: The output also contains text and the output is just a string which can not just the converted to a dictionary. Lets make it better with a more complex example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import ResponseSchema\n",
    "from langchain.output_parsers import StructuredOutputParser\n",
    "\n",
    "sentiment_schema = ResponseSchema(\n",
    "    name=\"sentiment\",\n",
    "    description=\"Is the text positive, neutral or negative? Only provide these words\",\n",
    ")\n",
    "subject_schema = ResponseSchema(\n",
    "    name=\"subject\", description=\"What subject is the text about? Use exactly one word.\"\n",
    ")\n",
    "price_schema = ResponseSchema(\n",
    "    name=\"price\",\n",
    "    description=\"How expensive was the product? Use None if no price was provided in the text\",\n",
    ")\n",
    "\n",
    "response_schemas = [sentiment_schema, subject_schema, price_schema]\n",
    "print(response_schemas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "format_instructions = parser.get_format_instructions()\n",
    "print(format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Interprete the text and evaluate the text.\n",
    "sentiment: is the text in a positive, neutral or negative sentiment?\n",
    "subject: What subject is the text about? Use exactly one word.\n",
    "\n",
    "Just return the JSON, do not add ANYTHING, NO INTERPRETATION!\n",
    "\n",
    "text: {input}\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template=template)\n",
    "\n",
    "format_instructions = parser.get_format_instructions()\n",
    "\n",
    "messages = prompt.format_messages(\n",
    "    input=\"I ordered Pizza Salami for 9.99$ and it was awesome!\",\n",
    "    format_instructions=format_instructions,\n",
    ")\n",
    "\n",
    "chat = ChatOpenAI(deployment_id = deployment_name,temperature=0.0)\n",
    "response = chat(messages)\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dict = parser.parse(response.content)\n",
    "output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autogpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
